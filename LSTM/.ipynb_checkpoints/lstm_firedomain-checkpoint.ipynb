{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### FIRE DOMAIN ONLY\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import cPickle\n",
    "from collections import defaultdict\n",
    "import sys, os, math, re\n",
    "os.environ['KERAS_BACKEND']='tensorflow'\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from pandas import HDFStore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data_100_4hyp/Inputs/fire_2.npy\n",
      "(70, 99, 1)\n",
      "Train on 70 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 0.3967 - accuracy: 0.0000e+00 - val_loss: 0.2606 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 0.3631 - accuracy: 0.0000e+00 - val_loss: 0.2152 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.2986 - accuracy: 0.0000e+00 - val_loss: 0.1876 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 3s 40ms/step - loss: 0.2860 - accuracy: 0.0000e+00 - val_loss: 0.1658 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 0.2499 - accuracy: 0.0000e+00 - val_loss: 0.1485 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 3s 41ms/step - loss: 0.2349 - accuracy: 0.0000e+00 - val_loss: 0.1337 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 3s 36ms/step - loss: 0.2045 - accuracy: 0.0000e+00 - val_loss: 0.1190 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 3s 36ms/step - loss: 0.1927 - accuracy: 0.0000e+00 - val_loss: 0.1031 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 3s 36ms/step - loss: 0.1535 - accuracy: 0.0000e+00 - val_loss: 0.0908 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 3s 36ms/step - loss: 0.1428 - accuracy: 0.0000e+00 - val_loss: 0.0807 - val_accuracy: 0.0000e+00\n",
      "./Data_100_4hyp/Inputs/fire_5.npy\n",
      "(70, 99, 1)\n",
      "Train on 70 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "70/70 [==============================] - 3s 45ms/step - loss: 0.2236 - accuracy: 0.0000e+00 - val_loss: 0.1762 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 3s 43ms/step - loss: 0.1711 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 4s 50ms/step - loss: 0.1454 - accuracy: 0.0000e+00 - val_loss: 0.1107 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 4s 54ms/step - loss: 0.1116 - accuracy: 0.0000e+00 - val_loss: 0.0940 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 4s 54ms/step - loss: 0.1075 - accuracy: 0.0000e+00 - val_loss: 0.0865 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 5s 67ms/step - loss: 0.0959 - accuracy: 0.0000e+00 - val_loss: 0.0847 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 4s 59ms/step - loss: 0.1017 - accuracy: 0.0000e+00 - val_loss: 0.0841 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 3s 44ms/step - loss: 0.0872 - accuracy: 0.0000e+00 - val_loss: 0.0838 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 3s 40ms/step - loss: 0.0910 - accuracy: 0.0000e+00 - val_loss: 0.0839 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 3s 36ms/step - loss: 0.0918 - accuracy: 0.0000e+00 - val_loss: 0.0841 - val_accuracy: 0.0000e+00\n",
      "./Data_100_4hyp/Inputs/fire_10.npy\n",
      "(70, 99, 1)\n",
      "Train on 70 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "70/70 [==============================] - 3s 45ms/step - loss: 0.3138 - accuracy: 0.0000e+00 - val_loss: 0.3549 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 4s 62ms/step - loss: 0.2768 - accuracy: 0.0000e+00 - val_loss: 0.2985 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 0.2203 - accuracy: 0.0000e+00 - val_loss: 0.2238 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 0.1593 - accuracy: 0.0000e+00 - val_loss: 0.1554 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 3s 42ms/step - loss: 0.1150 - accuracy: 0.0000e+00 - val_loss: 0.1149 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 0.0977 - accuracy: 0.0000e+00 - val_loss: 0.0987 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 4s 60ms/step - loss: 0.0914 - accuracy: 0.0000e+00 - val_loss: 0.0924 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 5s 74ms/step - loss: 0.0870 - accuracy: 0.0000e+00 - val_loss: 0.0887 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 4s 52ms/step - loss: 0.0792 - accuracy: 0.0000e+00 - val_loss: 0.0871 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 0.0811 - accuracy: 0.0000e+00 - val_loss: 0.0867 - val_accuracy: 0.0000e+00\n",
      "./Data_100_4hyp/Inputs/fire_20.npy\n",
      "(70, 99, 1)\n",
      "Train on 70 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "70/70 [==============================] - 5s 71ms/step - loss: 0.3701 - accuracy: 0.0000e+00 - val_loss: 0.2825 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 3s 45ms/step - loss: 0.3161 - accuracy: 0.0000e+00 - val_loss: 0.2310 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 4s 64ms/step - loss: 0.2529 - accuracy: 0.0000e+00 - val_loss: 0.2006 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 4s 53ms/step - loss: 0.2287 - accuracy: 0.0000e+00 - val_loss: 0.1757 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 0.1995 - accuracy: 0.0000e+00 - val_loss: 0.1548 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 5s 66ms/step - loss: 0.1703 - accuracy: 0.0000e+00 - val_loss: 0.1357 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 4s 54ms/step - loss: 0.1539 - accuracy: 0.0000e+00 - val_loss: 0.1184 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 0.1330 - accuracy: 0.0000e+00 - val_loss: 0.1021 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 0.1109 - accuracy: 0.0000e+00 - val_loss: 0.0928 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 4s 58ms/step - loss: 0.0995 - accuracy: 0.0000e+00 - val_loss: 0.0879 - val_accuracy: 0.0000e+00\n",
      "./Data_100_4hyp/Inputs/fire_50.npy\n",
      "(70, 99, 1)\n",
      "Train on 70 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "70/70 [==============================] - 4s 52ms/step - loss: 0.2675 - accuracy: 0.0000e+00 - val_loss: 0.1912 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 3s 47ms/step - loss: 0.2244 - accuracy: 0.0000e+00 - val_loss: 0.1556 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 4s 52ms/step - loss: 0.1806 - accuracy: 0.0000e+00 - val_loss: 0.1226 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.1387 - accuracy: 0.0000e+00 - val_loss: 0.1000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 2s 27ms/step - loss: 0.1075 - accuracy: 0.0000e+00 - val_loss: 0.0906 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 2s 31ms/step - loss: 0.0945 - accuracy: 0.0000e+00 - val_loss: 0.0898 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 2s 31ms/step - loss: 0.0850 - accuracy: 0.0000e+00 - val_loss: 0.0912 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 0.0850 - accuracy: 0.0000e+00 - val_loss: 0.0926 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 3s 50ms/step - loss: 0.0807 - accuracy: 0.0000e+00 - val_loss: 0.0936 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 4s 54ms/step - loss: 0.0846 - accuracy: 0.0000e+00 - val_loss: 0.0949 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "    max_sen_len = 100\n",
    "    dir_list = ['./Data_100_4hyp/']\n",
    "    input_flist = [ 'Inputs/fire_2.npy', 'Inputs/fire_5.npy', 'Inputs/fire_10.npy', 'Inputs/fire_20.npy', 'Inputs/fire_50.npy']\n",
    "    # output_flist = ['Outputs/res_fire2.npy']\n",
    "    output_flist = [ 'Outputs/res_fire2.npy', 'Outputs/res_fire5.npy', 'Outputs/res_fire10.npy', 'Outputs/res_fire20.npy', 'Outputs/res_fire50.npy']\n",
    "    # preds_flist = ['Preds/pred_fire2.npy']\n",
    "    preds_flist = [ 'Preds/pred_fire2.npy', 'Preds/pred_fire5.npy', 'Preds/pred_fire10.npy', 'Preds/pred_fire20.npy', 'Preds/pred_fire50.npy']\n",
    "    # weights_flist = []\n",
    "    weights_flist = [ 'Weights/weig_fire2.h5', 'Weights/weig_fire5.h5', 'Weights/weig_fire10.h5', 'Weights/weig_fire20.h5', 'Weights/weig_fire50.h5' ]\n",
    "    for dir_name in dir_list:\n",
    "\n",
    "        for index_ in range(0,5):\n",
    "\n",
    "            input_fname = input_flist[index_]\n",
    "            output_fname = output_flist[index_]\n",
    "            preds_fname = preds_flist[index_]\n",
    "            weight_fname = weights_flist[index_]\n",
    "\n",
    "            print (str (dir_name + input_fname))\n",
    "            dataset = np.load(str(dir_name)+input_fname)\n",
    "#             print(dataset.shape)\n",
    "            dataset = dataset.astype('float32')\n",
    "\n",
    "            # x=[]\n",
    "            # for i in range(0,100):\n",
    "\n",
    "            # \tx.append(i)\n",
    "            # plt.figure('data')\n",
    "            # for i in dataset:\n",
    "            # \tplt.plot(x,i)\n",
    "            # plt.show()\n",
    "\n",
    "            np.random.seed(7)\n",
    "            # np.random.shuffle(dataset)\n",
    "            dataset = np.reshape(dataset, (dataset.shape[0], dataset.shape[1], 1))\n",
    "\n",
    "            #################################\n",
    "            # split into train and test sets\n",
    "            val_split = 0.3\n",
    "            train_size = int(len(dataset) * (1.0 - val_split))\n",
    "            test_size = len(dataset) - train_size\n",
    "\n",
    "            train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "            ### Due to 101 values being present\n",
    "            x_train = train[:,:-1]\n",
    "            y_train = train[:,:-1]\n",
    "            print(y_train.shape)\n",
    "            x_test = test[:,:-1]\n",
    "            y_test = test[:,:-1]\n",
    "            #################################\n",
    "\n",
    "            #x, y = dataset[:,:-1], dataset[:,1:]\n",
    "\n",
    "            ############### change model from sequence prediction to last value prediction ###################\n",
    "\n",
    "            y_train_last = [[y_train[i,-1] for j in range(0,y_train.shape[1])] for i in range(0,y_train.shape[0])]\n",
    "\n",
    "            y_test_last = [[y_test[i,-1] for j in range(0,y_test.shape[1])] for i in range(0,y_test.shape[0])]\n",
    "\n",
    "            y_train_last = np.array(y_train_last)\n",
    "            y_test_last = np.array(y_test_last)\n",
    "            model = Sequential()\n",
    "            model.add (LSTM (1, input_shape = (100,1), return_sequences=True, stateful=False, dtype='float32', dropout=0.3, recurrent_dropout=0.3))\n",
    "            model.compile(loss=\"mse\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "            # model.fit (x_train, y_train, batch_size=1, epochs=20, validation_data=(x_test, y_test), shuffle=True)\n",
    "            model.fit (x_train, y_train_last, batch_size=1, epochs=10, validation_data=(x_test, y_test_last), shuffle=True)\n",
    "            predictions = model.predict(dataset[:,:])\n",
    "\n",
    "            with open(str(dir_name + preds_fname),'wb') as pr: \n",
    "            \tnp.save(pr,predictions)\n",
    "\n",
    "            with open(str(dir_name + output_fname),'wb') as res: \n",
    "            \tnp.save(res,y_test_last)\n",
    "\n",
    "            model.save_weights(str(dir_name + weight_fname))\n",
    "\n",
    "            # # load json and create model\n",
    "            # json_file = open('model_boul10.json', 'r')\n",
    "            # loaded_model_json = json_file.read()\n",
    "            # json_file.close()\n",
    "            # loaded_model = model_from_json(loaded_model_json)\n",
    "            # # load weights into new model\n",
    "            # loaded_model.load_weights(\"model_boul10.h5\")\n",
    "            # print(\"Loaded model from disk\")\n",
    "\n",
    "            # # evaluate loaded model on test data\n",
    "            # loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "            # score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "            # print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "\n",
    "    with open('model_architecture.json', 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "\n",
    "            ###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data_100_4hyp/Inputs/fire_50.npy\n",
      "(30, 99, 1)\n",
      "(100, 99, 1)\n",
      "./Data_100_4hyp/Inputs/fire_2.npy\n",
      "(30, 99, 1)\n",
      "(100, 99, 1)\n",
      "./Data_100_4hyp/Inputs/fire_5.npy\n",
      "(30, 99, 1)\n",
      "(100, 99, 1)\n",
      "./Data_100_4hyp/Inputs/fire_10.npy\n",
      "(30, 99, 1)\n",
      "(100, 99, 1)\n",
      "./Data_100_4hyp/Inputs/fire_20.npy\n",
      "(30, 99, 1)\n",
      "(100, 99, 1)\n"
     ]
    }
   ],
   "source": [
    "for dir_name in dir_list:\n",
    "\n",
    "        for index_ in range(0,5):\n",
    "            print (str (dir_name + input_fname))\n",
    "            input_fname = input_flist[index_]\n",
    "            output_fname = output_flist[index_]\n",
    "            preds_fname = preds_flist[index_]\n",
    "            weight_fname = weights_flist[index_]\n",
    "            data = str(dir_name)+output_fname\n",
    "            data = np.load(data)\n",
    "            print(data.shape)\n",
    "            my = str(dir_name)+preds_fname\n",
    "            my = np.load(my)\n",
    "            print(my.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
